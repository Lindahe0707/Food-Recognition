{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "#************************Performance Evaluation******************\n",
    "import numpy as np\n",
    "\n",
    "# Build the inception v3 network\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "model_inception = InceptionV3(include_top=False, weights='imagenet',input_shape=(300, 300, 3))\n",
    "\n",
    "#model_inception.summary()\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(model_inception)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.load_weights('/Users/apple/Downloads/inception_flatten_dense.h5')\n",
    "print('Model loaded.')\n",
    "\n",
    "#compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['categorical_accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is a little different from the paper.\n",
    "# I also evaluated the performance of Google Cloud Vision when I was doing the project which is not mentioned in the paper\n",
    "\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "# Build dictionary for reference\n",
    "meat_list = [\"beef\", \"chicken\", \"lamb\", \"pork\", \"tuna\", \"turkey\"]\n",
    "\n",
    "target_size = (300, 300)\n",
    "\n",
    "#Predict by CNN model \n",
    "def cnn_method(path):\n",
    "    img = load_img(path, target_size = target_size)\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1,) + x.shape)\n",
    "    x *= 1. /255\n",
    "    return meat_list[model.predict_classes(x)[0]]\n",
    "\n",
    "#Predict on Google Cloud Vision first, and then on our CNN model\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"Client's Json file\"\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "def combine_method(path):\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    # Performs label detection on the image file\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "\n",
    "    #Search the label containing the keyword in order\n",
    "    #If all labels do not contain the keyword, pass the image into the CNN model\n",
    "    for label in labels:\n",
    "        label_name = label.description.lower()\n",
    "        #print(labelname)\n",
    "        for meat in meat_list:\n",
    "            if meat in label_name:\n",
    "                return meat\n",
    "    return cnn_method(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beef'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test on single image\n",
    "combine_method('/Users/apple/Mcgill/689PROJECT/code/pictures/test/1_beef/000003.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate pictures in a file and calcuate the recall for each category of meat\n",
    "def eval_one_category(rel_path, meat_name, method):\n",
    "    total_pic = 0\n",
    "    count = 0\n",
    "    ab_path = os.path.abspath('')\n",
    "    for filename in os.listdir(ab_path + rel_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"): \n",
    "            total_pic += 1 \n",
    "            file_ab_name = os.path.join(ab_path, rel_path[1:], filename)\n",
    "            if method(file_ab_name) == meat_name:\n",
    "                #print(count)\n",
    "                count += 1\n",
    "    print(\"{} accuracy = {:.3f}\".format(meat_name, count/total_pic)) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/myenv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/apple/myenv/lib/python3.6/site-packages/PIL/Image.py:916: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken accuracy = 0.477\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the accuracy of combined method or CNN method performance on one meat category\n",
    "\n",
    "# For example\n",
    "eval_one_category(\"/pictures/test/2_chicken\",\"chicken\", cnn_method)\n",
    "\n",
    "eval_one_category(\"/pictures/test/2_chicken\",\"chicken\", combine_method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall model performance: recall and precision\n",
    "#meat_list = [\"beef\", \"chicken\", \"lamb\", \"pork\", \"tuna\", \"turkey\"]\n",
    "\n",
    "def eval_overall(method):\n",
    "\n",
    "    ab_path = os.path.abspath('')\n",
    "    rel_list = [\"/pictures/test/1_beef\",\"/pictures/test/2_chicken\",\n",
    "                \"/pictures/test/3_lamb\",\"/pictures/test/4_pork\",\n",
    "                \"/pictures/test/5_tuna\",\"/pictures/test/6_turkey\"]\n",
    "    \n",
    "    #tp_dict is for true positives, and predict_dict is for predicted as positives, actual_dict is for actual labels\n",
    "    tp_dict = {\"beef\":0, \"chicken\":0,\"lamb\":0, \"pork\":0,\"tuna\": 0,\"turkey\": 0}\n",
    "    predict_dict = {\"beef\":0, \"chicken\":0,\"lamb\":0, \"pork\":0,\"tuna\": 0,\"turkey\": 0}\n",
    "    actual_dict = {\"beef\":0, \"chicken\":0,\"lamb\":0, \"pork\":0,\"tuna\": 0,\"turkey\": 0}\n",
    "    \n",
    "    for m, p in zip(meat_list, rel_list):\n",
    "        for filename in os.listdir(ab_path + p):\n",
    "            if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"): \n",
    "                file_ab_name = os.path.join(ab_path, p[1:], filename)\n",
    "                actual_dict[m] += 1 # the actual label \n",
    "                temp = method(file_ab_name) # the predicted label\n",
    "                predict_dict[temp] += 1\n",
    "                if temp == m:\n",
    "                    tp_dict[m] += 1 # the true positives\n",
    "    #Print (tp_dict, predict_dict, actual_dict)\n",
    "    for m in meat_list:\n",
    "        print(\"{} precision = {:.3f}\".format(m, tp_dict[m]/predict_dict[m])) \n",
    "        print(\"{} recall = {:.3f}\".format(m, tp_dict[m]/actual_dict[m]))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/myenv/lib/python3.6/site-packages/PIL/Image.py:916: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n",
      "/Users/apple/myenv/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:725: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12 bytes but only got 10. Skipping tag 42037\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beef': 82, 'chicken': 86, 'lamb': 59, 'pork': 65, 'tuna': 63, 'turkey': 90} {'beef': 148, 'chicken': 150, 'lamb': 85, 'pork': 101, 'tuna': 75, 'turkey': 107} {'beef': 113, 'chicken': 109, 'lamb': 102, 'pork': 134, 'tuna': 101, 'turkey': 107}\n",
      "beef precision = 0.554\n",
      "beef recall = 0.726\n",
      "chicken precision = 0.573\n",
      "chicken recall = 0.789\n",
      "lamb precision = 0.694\n",
      "lamb recall = 0.578\n",
      "pork precision = 0.644\n",
      "pork recall = 0.485\n",
      "tuna precision = 0.840\n",
      "tuna recall = 0.624\n",
      "turkey precision = 0.841\n",
      "turkey recall = 0.841\n"
     ]
    }
   ],
   "source": [
    "eval_overall(cnn_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
